{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_Taxi-v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MnG7K_JY3nVW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting up OpenAi Gym Environment :"
      ]
    },
    {
      "metadata": {
        "id": "zu8zChlelBJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "605700a8-ada6-4256-e017-ae32fa083472"
      },
      "cell_type": "code",
      "source": [
        "!pip install cmake 'gym[atari]' scipy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.11.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.2)\n",
            "Requirement already satisfied: atari_py>=0.1.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.0.0)\n",
            "Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->gym[atari]) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9_CiDie5lFaV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YX--xwAalR9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v2\").env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCWNHW6YlVdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "721d7c4d-f8ee-4c74-a2f6-b81458f96d9f"
      },
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k1_G0fOklWiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1688f10-cf51-494c-def7-4f972a70845f"
      },
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "2nbwm5zFmZJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "b85bd3d1-2a66-47f4-d403-3f6932a8e1b6"
      },
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iYeE9rmAmbgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17281a1b-1910-4c8c-e76f-c5c919ce4d6b"
      },
      "cell_type": "code",
      "source": [
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jus8BWVemqpc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "state = env.encode(3,1,2,0) # (taxi row, taxi column, passenger index, destination index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLY4j7wsnrgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "033838ee-01db-4a80-8a20-ccf283c7e9f3"
      },
      "cell_type": "code",
      "source": [
        "print(\"State\", state)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State 328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ew-yRUR8nu96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env.s = state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9K12nldLn4cB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "62932b2a-d86e-4ad3-983b-276fa56f2c7a"
      },
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b6z9YKOFn5n9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "74eb8da2-135e-4263-d8fc-84947efb46f1"
      },
      "cell_type": "code",
      "source": [
        "env.P[328]   # This dictionary has the structure {action: [(probability, nextstate, reward, done)]}."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 428, -1, False)],\n",
              " 1: [(1.0, 228, -1, False)],\n",
              " 2: [(1.0, 348, -1, False)],\n",
              " 3: [(1.0, 328, -1, False)],\n",
              " 4: [(1.0, 328, -10, False)],\n",
              " 5: [(1.0, 328, -10, False)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "AxC_h5j9pNcZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Solving without Reinforcement Learning :"
      ]
    },
    {
      "metadata": {
        "id": "ReGmTkZxpRIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The env.action_space.sample() method automatically selects one random action from set of all possible actions."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hqkKN43Pps8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a7d6dca-2419-49d7-e3a6-7925476ca622"
      },
      "cell_type": "code",
      "source": [
        "env.s = 328 # setting environment to illustration state\n",
        "\n",
        "epochs = 0\n",
        "penalties, reward = 0,0\n",
        "\n",
        "frames = []  # For animation\n",
        "done = False\n",
        "\n",
        "while not done : \n",
        "  action = env.action_space.sample()\n",
        "  state , reward, done, info = env.step(action)\n",
        "#   print(\"state : {} , reward : {} , done : {}, info : {}\".format(state, reward, done,info))\n",
        "  \n",
        "  if reward == -10:\n",
        "    penalties += 1\n",
        "    \n",
        "  # Put each rendereed frame into dict for animation\n",
        "  frames.append({\n",
        "      'frame' : env.render(mode='ansi'),\n",
        "      'state' : state,\n",
        "      'action': action,\n",
        "      'reward' : reward\n",
        "  })\n",
        "  \n",
        "  epochs +=1\n",
        "  \n",
        "print(\"Timesteps taken : {}\".format(epochs))\n",
        "print(\"Penalties incurred : {}\".format(penalties))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timesteps taken : 256\n",
            "Penalties incurred : 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IZ39I7VTq4OC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Displaying the Frames :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tv8Os7g3r1DM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "de1e31c3-2bd7-4457-d984-325ed413c455"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def print_frames(frames):\n",
        "  for i, frame in enumerate (frames):\n",
        "    clear_output(wait = True)\n",
        "    print(frame['frame'].getvalue())\n",
        "    print(f\"Timestep: {i + 1}\")\n",
        "    print(f\"State: {frame['state']}\")\n",
        "    print(f\"Action: {frame['action']}\")\n",
        "    print(f\"Reward: {frame['reward']}\")\n",
        "    sleep(.7)\n",
        "\n",
        "    \n",
        "print_frames(frames)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 256\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fdcZRhOs9RQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjLyNKKu0Vvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q- Learning :"
      ]
    },
    {
      "metadata": {
        "id": "l7r9mi9f0XHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initializing the Q-table to a 500 x 6 matrix of zeroes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZaSzimpK4dU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOF9bc5iK6dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FapsU3X4LQdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "136cc4c6-d53f-4346-e47e-d64a1ffa2ea4"
      },
      "cell_type": "code",
      "source": [
        "q_table"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "apvEeXtPLT4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "301063cb-fe66-4a9d-8ba5-79733f233cb2"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\"\"\"Training the Agent\"\"\"\n",
        "\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1     # Learning Rate\n",
        "gamma = 0.6     # Discount Factor\n",
        "epsilon = 0.1   # Exploration Factor\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1,100001):\n",
        "  state = env.reset()\n",
        "  \n",
        "  epochs, penalties, reward = 0, 0, 0\n",
        "  done = False\n",
        "  \n",
        "  while not done:\n",
        "    if random.uniform(0,1) < epsilon:\n",
        "      action = env.action_space.sample() # Explore action space\n",
        "    else:\n",
        "      action = np.argmax(q_table[state]) # Exploit learned values\n",
        "      \n",
        "    next_state , reward, done, info = env.step(action)\n",
        "    \n",
        "    old_value = q_table[state, action]\n",
        "    next_max = np.max(q_table[next_state])\n",
        "    \n",
        "    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "    q_table[state, action] = new_value\n",
        "    \n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "      \n",
        "    state = next_state\n",
        "    epochs +=1\n",
        "    \n",
        "  if i % 100 == 0:\n",
        "    clear_output(wait = True)\n",
        "    print(f\"Episode : {i}\")\n",
        "    \n",
        "    \n",
        "print(\"Training Finished. \\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode : 100000\n",
            "Training Finished. \n",
            "\n",
            "CPU times: user 46.9 s, sys: 2.72 s, total: 49.7 s\n",
            "Wall time: 48.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RKL4W_6sYnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "da6a21a1-78c0-404e-d78c-c80b14d3e579"
      },
      "cell_type": "code",
      "source": [
        "q_table[328]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -2.40420798,  -2.27325184,  -2.41132732,  -2.36185445,\n",
              "       -10.74917054, -10.51017477])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "xK-XYxaxs4in",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cz8TP1lCtBgb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Agent:"
      ]
    },
    {
      "metadata": {
        "id": "99SH1P15tEg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5f099bec-4044-48d7-8c3d-31303aeefce1"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Evaluate agent's performance after Q-Learning\"\"\"\n",
        "\n",
        "total_epochs , total_penalties = 0,0\n",
        "episodes = 100\n",
        "\n",
        "for _ in range(episodes):\n",
        "  state = env.reset()\n",
        "  epochs , penalties, reward = 0,0,0\n",
        "  \n",
        "  done = False\n",
        "  \n",
        "  while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    state , reward, done, info = env.step(action)\n",
        "    \n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "      \n",
        "    epochs += 1\n",
        "    \n",
        "  total_penalties += penalties\n",
        "  total_epochs += epochs\n",
        "  \n",
        "  \n",
        "print(f\"Results after {episodes} episodes: \")\n",
        "print(f\"Average timesteps per episode : {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode : {total_penalties / episodes}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 100 episodes: \n",
            "Average timesteps per episode : 12.73\n",
            "Average penalties per episode : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "isDELiH9uB1P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Displaying frames of the Q-Learning algo:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMj5W8zxxWfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3675548e-031d-4140-a41c-5856a26a25b0"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Evaluate agent's performance after Q-Learning\"\"\"\n",
        "\n",
        "total_epochs , total_penalties = 0,0\n",
        "episodes = 100\n",
        "\n",
        "frames = [] # For animation\n",
        "\n",
        "for _ in range(episodes):\n",
        "  state = env.reset()\n",
        "  epochs , penalties, reward = 0,0,0\n",
        "  \n",
        "  done = False\n",
        "  \n",
        "  while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    state , reward, done, info = env.step(action)\n",
        "    \n",
        "    if reward == -10:\n",
        "      penalties += 1\n",
        "      \n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward,\n",
        "        'episode': _\n",
        "    })\n",
        "    \n",
        "    epochs += 1\n",
        "    \n",
        "  total_penalties += penalties\n",
        "  total_epochs += epochs\n",
        "  \n",
        "  \n",
        "print(f\"Results after {episodes} episodes: \")\n",
        "print(f\"Average timesteps per episode : {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode : {total_penalties / episodes}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 100 episodes: \n",
            "Average timesteps per episode : 12.66\n",
            "Average penalties per episode : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lW7mHmJ7yKSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "1dbb89de-3f18-43ff-ff9e-8fb86774a29f"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'].getvalue())\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        print(f\"Episode: {frame['episode']}\")\n",
        "\n",
        "        sleep(.1)\n",
        "        \n",
        "print_frames(frames)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 1266\n",
            "State: 85\n",
            "Action: 5\n",
            "Reward: 20\n",
            "Episode: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QwvfgkQyPGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}